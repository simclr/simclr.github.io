<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>SimCLR: A Simple Framework for Contrastive Learning of Visual Representations</title>
      <link rel="stylesheet" type="text/css" href="stylesheet.css"/>
      <!-- <link rel="shortcut icon" href="../../images/taco.png"> -->
      <script>
         function play(path) {{
           var player = document.getElementById('player');
           player.src = path;
           player.play();
         }}
      </script>
      <style>
         .audio-cell {
         /* Center audio widgets in the table cell. */
         text-align: center;
         padding-bottom: 1px;
         padding-top: 1px;
         }
         .audio-cell-padded {
         text-align: center;
         padding-bottom: 10px;
         padding-top: 10px;
         }
         .audio-header {
         /* Don't wrap header text. */
         white-space: nowrap;
         /* Some breaking space between headers for readability. */
         padding-right: 5px;
         padding-left: 5px;
         }
         .reference-cell {
         /* For uniformity and to wrap long reference text, limit the reference cell's width. */
         width: 25%;
         padding-top: 20px;
         padding-bottom: 20px;
         }
         .sample audio {
         vertical-align: middle;
         padding-left: 3px;
         padding-right: 3px;
         }
         .round-button {
         box-sizing: border-box;
         display:block;
         width:30px;
         height:30px;
         padding-top: 8px;
         padding-left: 3px;
         line-height: 6px;
         border: 1.2px solid #000;
         border-radius: 50%;
         color: #000;
         text-align:center;
         background-color: rgba(0,0,0,0.00);
         font-size:6px;
         box-shadow: 0px 0px 2px rgba(0,0,0,1);
         transition: all 0.2s ease;
         }
         .round-button:hover {
         background-color: rgba(0,0,0,0.0);
         box-shadow: 0px 0px 4px rgba(0,0,0,1);
         }
         .round-button:active {
         background-color: rgba(0,0,0,0.01);
         box-shadow: 0px 0px 1px rgba(0,0,0,1);
         }
      </style>
   </head>
   <body>
     <div class="main">
       <article>
         <header>
           <h1>A Simple Framework for Contrastive Learning of Visual Representations
	     [<a href="https://arxiv.org/pdf/2002.05709.pdf">pdf</a>]</h1>
         </header>
      </article>
	<img src="SimCLR.png" style="float:right; width: 450px; margin-left: 20px; display: block;" alt="SimCLR encourages different augmentations of each image to lie near each other in the representation space and far from augmentations of other images."/>	
      <div>
         <p>
	   <a href="https://scholar.google.com/citations?user=KoXUMbsAAAAJ&hl=en">Ting Chen</a>,
	   <a href="https://scholar.google.com/citations?user=1O3RPmsAAAAJ&hl=en">Simon Kornblith</a>,
	   <a href="http://norouzi.github.io">Mohammad Norouzi</a>,
	   <a href="https://www.cs.toronto.edu/~hinton/">Geoffrey Hinton</a>, ICML 2020</p>
      </div>
      <div>
      <p><b>Abstract:</b> This paper presents SimCLR: a simple
framework for contrastive learning of visual representations. We
simplify recently proposed contrastive self-supervised learning
algorithms without requiring specialized architectures or a memory
bank. In order to understand what enables the contrastive prediction
tasks to learn useful representations, we systematically study the
major components of our framework. We show that (1) composition of
data augmentations plays a critical role in defining effective
predictive tasks, (2) introducing a learnable nonlinear transformation
between the representation and the contrastive loss substantially
improves the quality of the learned representations, and (3)
contrastive learning benefits from larger batch sizes and more
training steps compared to supervised learning. By combining these
findings, we are able to considerably outperform previous methods for
self-supervised and semi-supervised learning on ImageNet. A linear
classifier trained on self-supervised representations learned by
SimCLR achieves 76.5% top-1 accuracy, which is a 7% relative
improvement over previous state-of-the-art, matching the performance
of a supervised ResNet-50. When fine-tuned on only 1% of the labels,
we achieve 85.8% top-5 accuracy, outperforming AlexNet with 100X fewer
	labels.</p>
      <p><a href="https://github.com/google-research/simclr"><b>Code on github</b></a></p>
      <p><a href="https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html"><b>Google AI blog post</b></a></p>
      <h3>
        Follow-up work:
      </h3>
      <p>
	<ul>
	  <li style="margin: 5px; margin-left: 0; padding-bottom: 3px">Big Self-Supervised Models are Strong Semi-Supervised Learners [<a href="https://arxiv.org/pdf/2006.10029.pdf">pdf</a>] (NeurIPS'20)</li>
	  <li style="margin: 5px; margin-left: 0; padding-bottom: 3px">Big Self-Supervised Models Advance Medical Image Classification [<a href="https://arxiv.org/pdf/2101.05224.pdf">pdf</a>]</li>
	</ul>
      </p>
      </div>
   </body>
</html>
